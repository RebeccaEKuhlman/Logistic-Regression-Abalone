{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extending Logistic Regression\n",
    "By: <ul>\n",
    "<li> Rebecca Kuhlman </li>\n",
    "<li> Sam Yao </li>\n",
    "<li> Micheal  </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Preparation and Overview</h2>\n",
    "\n",
    "    [2 points] Explain the task and what business-case or use-case it is designed to solve (or designed to investigate). Detail exactly what the classification task is and what parties would be interested in the results. For example, would the model be deployed or used mostly for offline analysis? As in previous labs, also detail how good the classifier needs to perform in order to be useful.\n",
    "    [.5 points] (mostly the same processes as from previous labs) Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis. Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created). Provide a breakdown of the variables after preprocessing (such as the mean, std, etc. for all variables, including numeric and categorical).\n",
    "    [.5 points] Divide your data into training and testing data using an 80% training and 20% testing split. Use the cross validation modules that are part of scikit-learn. Argue \"for\" or \"against\" splitting your data using an 80/20 split. That is, why is the 80/20 split appropriate (or not) for your dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Attribute Information:\n",
    "\n",
    "   1. Wife's age                     (numerical)\n",
    "   2. Wife's education               (categorical)      1=low, 2, 3, 4=high\n",
    "   3. Husband's education            (categorical)      1=low, 2, 3, 4=high\n",
    "   4. Number of children ever born   (numerical)\n",
    "   5. Wife's religion                (binary)           0=Non-Islam, 1=Islam\n",
    "   6. Wife's now working?            (binary)           0=Yes, 1=No\n",
    "   7. Husband's occupation           (categorical)      1, 2, 3, 4\n",
    "   8. Standard-of-living index       (categorical)      1=low, 2, 3, 4=high\n",
    "   9. Media exposure                 (binary)           0=Good, 1=Not good\n",
    "   10. Contraceptive method used     (class attribute)  1=No-use\n",
    "                                                        2=Long-term\n",
    "                                                        3=Short-term"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<bound method NDFrame.describe of       Wife's age  Wife's education  Husband's education  Number of children  \\\n0             24                 2                    3                   3   \n1             45                 1                    3                  10   \n2             43                 2                    3                   7   \n3             42                 3                    2                   9   \n4             36                 3                    3                   8   \n...          ...               ...                  ...                 ...   \n1468          33                 4                    4                   2   \n1469          33                 4                    4                   3   \n1470          39                 3                    3                   8   \n1471          33                 3                    3                   4   \n1472          17                 3                    3                   1   \n\n      Religion  Wife's working?  Husband's occupation  \\\n0            1                1                     2   \n1            1                1                     3   \n2            1                1                     3   \n3            1                1                     3   \n4            1                1                     3   \n...        ...              ...                   ...   \n1468         1                0                     2   \n1469         1                1                     1   \n1470         1                0                     1   \n1471         1                0                     2   \n1472         1                1                     2   \n\n      Standard-of-living index  Media exposure  Contraceptive method used  \n0                            3               0                          1  \n1                            4               0                          1  \n2                            4               0                          1  \n3                            3               0                          1  \n4                            2               0                          1  \n...                        ...             ...                        ...  \n1468                         4               0                          3  \n1469                         4               0                          3  \n1470                         4               0                          3  \n1471                         2               0                          3  \n1472                         4               0                          3  \n\n[1473 rows x 10 columns]>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/cmc/cmc.data\",\n",
    "                 names=[\"Wife's age\",\"Wife's education\",\"Husband's education\",\n",
    "                        \"Number of children\",\"Religion\",\"Wife's working?\"\n",
    "                        ,\"Husband's occupation\",\"Standard-of-living index\",\"Media exposure\", \"Contraceptive method used\"])\n",
    "df.describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Suggested we go back to wine dataset, as its more interesting than abalone dataset\n",
    "- If not, We could look for another dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling (5 points total)\n",
    "\n",
    "    The implementation of logistic regression must be written only from the examples given to you by the instructor. No credit will be assigned to teams that copy implementations from another source, regardless of if the code is properly cited.\n",
    "    [2 points] Create a custom, one-versus-all logistic regression classifier using numpy and scipy to optimize. Use object oriented conventions identical to scikit-learn. You should start with the template developed by the instructor in the course. You should add the following functionality to the logistic regression classifier:\n",
    "        Ability to choose optimization technique when class is instantiated: either steepest ascent, stochastic gradient ascent, and {Newton's method/Quasi Newton methods}.\n",
    "        Update the gradient calculation to include a customizable regularization term (either using no regularization, L1 regularization, L2 regularization, or both L1 and L2 regularization). Associate a cost with the regularization term, \"C\", that can be adjusted when the class is instantiated.\n",
    "    [1.5 points] Train your classifier to achieve good generalization performance. That is, adjust the optimization technique and the value of the regularization term(s) \"C\" to achieve the best performance on your test set. Visualize the performance of the classifier versus the parameters you investigated. Is your method of selecting parameters justified? That is, do you think there is any \"data snooping\" involved with this method of selecting parameters?\n",
    "    [1.5 points] Compare the performance of your \"best\" logistic regression optimization procedure to the procedure used in scikit-learn. Visualize the performance differences in terms of training time and classification performance. Discuss the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deployment (1 points total)\n",
    "\n",
    "        Which implementation of logistic regression would you advise be used in a deployed machine learning model, your implementation or scikit-learn (or other third party)? Why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exceptional Work (1 points total)\n",
    "\n",
    "    You have free reign to provide additional analyses. One idea: Update the code to use either \"one-versus-all\" or \"one-versus-one\" extensions of binary to multi-class classification.\n",
    "    Required for 7000 level students: Choose ONE of the following:\n",
    "        Option One: Implement an optimization technique for logistic regression using mean square error as your objective function (instead of maximum likelihood). Derive the gradient updates for the Hessian and use Newton's method to update the values of \"w\". Then answer, which process do you prefer: maximum likelihood OR minimum mean-squared error?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
